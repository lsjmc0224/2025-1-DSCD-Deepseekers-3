# test_youtube_crawling.py

import asyncio
from datetime import datetime

from app.core.db import SessionLocal
from app.models import Keywords
from app.crawler.repositories import CrawlingRepository
from app.crawler.sources.youtube import YouTubeCrawler


async def main():
    db = SessionLocal()

    try:
        # âœ… 1. í…ŒìŠ¤íŠ¸ìš© í‚¤ì›Œë“œ ì„ íƒ
        keyword_obj = db.query(Keywords).first()
        if not keyword_obj:
            print("âŒ [ERROR] í‚¤ì›Œë“œ í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # âœ… 2. í¬ë¡¤ë§ ëŒ€ìƒ ê¸°ê°„ ì§€ì • (YYYYMMDD)
        starttime = "20241001"
        endtime = "20241031"

        print(f"\nğŸ” YouTube í¬ë¡¤ë§ ì‹œì‘: '{keyword_obj.keyword}' | {starttime} ~ {endtime}")
        crawler = YouTubeCrawler()

        # âœ… 3. í¬ë¡¤ë§ ì‹¤í–‰
        result = await crawler.crawl(
            keyword=keyword_obj,
            max_videos=5,
            max_comments=20,
            published_after=starttime,
            published_before=endtime
        )

        videos = result["videos"]
        comments = result["comments"]
        channels = result["channels"]

        print(f"ğŸ“º ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ: {len(videos)}ê±´")
        print(f"ğŸ’¬ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ: {len(comments)}ê±´")
        print(f"ğŸ“¡ ì±„ë„ ìˆ˜ì§‘ ì™„ë£Œ: {len(channels)}ê±´")

        if not videos:
            print("âš ï¸ ì˜ìƒì´ ì—†ì–´ ì €ì¥ì„ ìƒëµí•©ë‹ˆë‹¤.")
            return

        # âœ… 4. ì €ì¥ ìˆ˜í–‰
        repo = CrawlingRepository(db)
        saved_counts = repo.create_youtube_data(
            channels=channels,
            videos=videos,
            comments=comments
        )

        # âœ… 5. ì €ì¥ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
        if saved_counts is None:
            print("âŒ [ERROR] DB ì €ì¥ ì‹¤íŒ¨ë¡œ ì¸í•´ ì €ì¥ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        print("\nğŸ’¾ DB ì €ì¥ ê²°ê³¼:")
        for k, v in saved_counts.items():
            print(f" - {k}: {v}")

    finally:
        db.close()


if __name__ == "__main__":
    asyncio.run(main())
