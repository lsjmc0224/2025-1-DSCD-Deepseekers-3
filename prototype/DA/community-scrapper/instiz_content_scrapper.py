import urllib.request
import datetime
import pandas as pd
import sys
from bs4 import BeautifulSoup
from lxml import html
import re
import urllib.parse
import os

def get_instiz_keyword_data(keyword: str, starttime: str, endtime: str) -> pd.DataFrame:
    """
    ğŸ“Œ ì¸ìŠ¤í‹°ì¦ˆ 'ìµëª…ì¡ë‹´' ê²Œì‹œíŒì—ì„œ íŠ¹ì • í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ê¸€ë“¤ì„ ìˆ˜ì§‘í•˜ëŠ” í¬ë¡¤ëŸ¬
    """

    title, time_list, contents, url_list, view, like, comment, cate, search_keyword = [], [], [], [], [], [], [], [], []
    base_url = "https://www.instiz.net"
    encoded_keyword = urllib.parse.quote(keyword, safe='')

    now_year = datetime.datetime.now().year
    today = pd.to_datetime(datetime.datetime.now().strftime('%Y.%m.%d'))

    os.makedirs("data", exist_ok=True)

    for page in range(1, 100):  # ì¶©ë¶„íˆ ë§ì€ í˜ì´ì§€ê¹Œì§€ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •
        try:
            full_url = (
                f'{base_url}/name?page={page}&category=1'
                f'&k={encoded_keyword}&stype=9&starttime={starttime}&endtime={endtime}'
            )
            print(f"[DEBUG] ê²€ìƒ‰ URL: {full_url}")

            response = urllib.request.urlopen(full_url)
            soup = BeautifulSoup(response.read().decode('utf-8'), 'html.parser')
            rows = soup.select('tr#detour')

            # â—ê²Œì‹œê¸€ì´ ì—†ìœ¼ë©´ break
            if not rows:
                print(f"[INFO] Page {page}ì—ì„œ ë” ì´ìƒ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            for row in rows:
                title_cell = row.select_one('td.listsubject a')
                if not title_cell or not title_cell.has_attr('href'):
                    continue

                post_href = title_cell['href']
                post_url = base_url + post_href.replace('..', '')

                # ì œëª©
                titlestr = title_cell.get_text(strip=True)
                title.append(titlestr)

                # URL
                url_list.append(post_url)

                # ë‚ ì§œ
                time_cell = row.select_one('td.listno.regdate')
                if time_cell:
                    timestr = time_cell.get_text(strip=True)
                    full_time = f"{now_year}.{timestr}"
                    try:
                        parsed_time = pd.to_datetime(full_time, format="%Y.%m.%d %H:%M")
                    except:
                        parsed_time = pd.to_datetime(full_time, format="%Y.%m.%d")
                    time_list.append(parsed_time)
                else:
                    time_list.append(today)

                # ì¡°íšŒìˆ˜, ì¶”ì²œìˆ˜
                listnos = row.select('td.listno')
                view.append(listnos[-2].get_text(strip=True) if len(listnos) >= 3 else '')
                like.append(listnos[-1].get_text(strip=True) if len(listnos) >= 3 else '')

                # ëŒ“ê¸€ ìˆ˜
                comment_span = row.select_one('span.cmt2')
                comment.append(comment_span.get_text(strip=True) if comment_span else '0')

                # ì¹´í…Œê³ ë¦¬, í‚¤ì›Œë“œ
                cate.append('instiz')
                search_keyword.append(keyword)

                # âœ… ë³¸ë¬¸ í¬ë¡¤ë§
                try:
                    post_resp = urllib.request.urlopen(post_url)
                    post_html = post_resp.read()
                    doc = html.fromstring(post_html)

                    content_div = doc.get_element_by_id('memo_content_1')

                    # script, style, img ì œê±°
                    for tag in content_div.xpath('.//script | .//style | .//img'):
                        tag.getparent().remove(tag)

                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ & ê³µë°± ì •ë¦¬
                    text = content_div.text_content()
                    clean_text = re.sub(r'\s+', ' ', text).strip()
                    contents.append(clean_text)

                except Exception as e:
                    print(f"ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨ ({post_url}): {e}", file=sys.stderr)
                    contents.append('')

        except Exception as e:
            print(f"Error on page {page}: {e}", file=sys.stderr)
            continue

    instiz_df = pd.DataFrame({
        'title': title,
        'time': time_list,
        'contents': contents,
        'url': url_list,
        'view': view,
        'like': like,
        'comment': comment,
        'cate': cate,
        'keyword': search_keyword,
    })

    print(f"[âœ“] instiz: ì´ {len(instiz_df)}ê°œ ê²Œì‹œê¸€ ì¶”ì¶œ ì™„ë£Œ")

    save_path = "data/instiz_keyword_data.csv"
    try:
        instiz_df.to_csv(save_path, index=False, encoding='utf-8-sig')
        print(f"[ğŸ“] ë°ì´í„°ê°€ {save_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"[âš ï¸] CSV ì €ì¥ ì‹¤íŒ¨: {e}", file=sys.stderr)

    return instiz_df

if __name__ == "__main__":
    get_instiz_keyword_data(keyword='ë°¤í‹°ë¼ë¯¸ìˆ˜', starttime='20241201', endtime='20241231')
